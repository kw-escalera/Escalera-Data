{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a8d0c6-fd73-4115-9100-7482738baa2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c25c9d86-0759-48ee-9c93-42994c7cc836 chfdrcvtwmkysb0a6nv8bl affd6b5a-347b-4a8a-871d-a457c91e2c31\n",
      "Total_rec  3138\n",
      "Records collected: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:   8%|█████▍                                                           | 1/12 [00:06<01:15,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  17%|██████████▊                                                      | 2/12 [00:12<01:02,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  25%|████████████████▎                                                | 3/12 [00:20<01:01,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  33%|█████████████████████▋                                           | 4/12 [00:28<01:00,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  42%|███████████████████████████                                      | 5/12 [00:39<01:01,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 1498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  50%|████████████████████████████████▌                                | 6/12 [00:49<00:55,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 1748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  58%|█████████████████████████████████████▉                           | 7/12 [00:58<00:45,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  67%|███████████████████████████████████████████▎                     | 8/12 [01:07<00:36,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 2245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  75%|████████████████████████████████████████████████▊                | 9/12 [01:16<00:27,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 2440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  83%|█████████████████████████████████████████████████████▎          | 10/12 [01:25<00:18,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 2690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  92%|██████████████████████████████████████████████████████████▋     | 11/12 [01:33<00:08,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 2940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records: 100%|████████████████████████████████████████████████████████████████| 12/12 [01:44<00:00,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 3078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_rec  2574\n",
      "Records collected: 3328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  10%|██████▌                                                          | 1/10 [00:07<01:05,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 3572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  20%|█████████████                                                    | 2/10 [00:14<00:58,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 3822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  30%|███████████████████▌                                             | 3/10 [00:22<00:53,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 4072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  40%|██████████████████████████                                       | 4/10 [00:29<00:44,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 4322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  50%|████████████████████████████████▌                                | 5/10 [00:36<00:36,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 4572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  60%|███████████████████████████████████████                          | 6/10 [00:45<00:31,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 4808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  70%|█████████████████████████████████████████████▌                   | 7/10 [00:55<00:25,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 5039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  80%|████████████████████████████████████████████████████             | 8/10 [01:03<00:16,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 5267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  90%|██████████████████████████████████████████████████████████▌      | 9/10 [01:17<00:10, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 5485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records: 100%|████████████████████████████████████████████████████████████████| 10/10 [01:21<00:00,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 5559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_rec  1917\n",
      "Records collected: 5809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  14%|█████████▍                                                        | 1/7 [00:06<00:36,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 6059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  29%|██████████████████▊                                               | 2/7 [00:13<00:33,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 6309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  43%|████████████████████████████▎                                     | 3/7 [00:19<00:26,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 6559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  57%|█████████████████████████████████████▋                            | 4/7 [00:28<00:22,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 6809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  71%|███████████████████████████████████████████████▏                  | 5/7 [00:36<00:15,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 7059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records:  86%|████████████████████████████████████████████████████████▌         | 6/7 [00:44<00:07,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching records: 100%|██████████████████████████████████████████████████████████████████| 7/7 [00:53<00:00,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records collected: 7470\n",
      "0:04:20.377503\n",
      "### Data Collection Complete ###\n",
      "Total records collected: 7470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import websocket\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "message_count = 0\n",
    "response_data = None  # Global variable to store response\n",
    "fina_data = {}  # Store all fetched data globally\n",
    "authToken = ''\n",
    "workspaceID = ''\n",
    "correlationId = ''\n",
    "cookies = ''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def driver_get_tokens():\n",
    "    from seleniumwire import webdriver\n",
    "    global authToken,workspaceID,correlationId,cookies\n",
    "    driver = webdriver.Chrome()\n",
    "    today_date = datetime.today().strftime('%Y%m%d')\n",
    "    driver.get(f\"https://bexar.tx.publicsearch.us/results?department=RP&limit=50&offset=0&recordedDateRange=20200101%2C{today_date}&searchOcrText=true&searchType=quickSearch&searchValue=%22Foreclosure%22&viewType=card\")\n",
    "    time.sleep(2)\n",
    "    for request in driver.requests:\n",
    "        if \"Cookie\" in request.headers:\n",
    "            if \"authToken\" in request.headers.get('cookie', None):\n",
    "                cookies = request.headers.get('cookie', None)\n",
    "        if request.response and 'Upgrade' in request.response.headers and request.response.headers['Upgrade'] == 'websocket':\n",
    "            \n",
    "            for message in request.ws_messages:\n",
    "                if 'authToken' in message.content and \"limit\" in message.content and \"workspaceID\" in message.content:  # Capture messages sent by the browser\n",
    "                    data = json.loads(message.content)\n",
    "                    authToken = data[\"authToken\"]\n",
    "                    workspaceID = data[\"payload\"][\"workspaceID\"]\n",
    "                    correlationId = data[\"correlationId\"]\n",
    "                    print(authToken,workspaceID,correlationId)\n",
    "                    break\n",
    "    driver.close()\n",
    "def on_open(ws):\n",
    "    global start_date, end_date\n",
    "    offset = ws.custom_offset  # Access custom attribute\n",
    "    message = {\n",
    "        'type': '@kofile/FETCH_DOCUMENTS/v4',\n",
    "        'payload': {\n",
    "            'query': {\n",
    "                'limit': '250',\n",
    "                'offset': str(offset),\n",
    "                'department': 'RP',\n",
    "                'recordedDateRange': f'{start_date.strftime(\"%Y%m%d\")},{end_date.strftime(\"%Y%m%d\")}',\n",
    "                'searchOcrText': True,\n",
    "                'searchType': 'quickSearch',\n",
    "                'searchValue': 'Foreclosure'\n",
    "            },\n",
    "            'workspaceID': 'qgi33r8r3rq7m4f4zz8vc8'\n",
    "        },\n",
    "        'authToken': authToken,\n",
    "        'correlationId': correlationId,\n",
    "        'sync': True\n",
    "    }\n",
    "    ws.send(json.dumps(message))\n",
    "\n",
    "def on_message(ws, message):\n",
    "    global response_data\n",
    "    response_data = message  # Store message in global variable\n",
    "    ws.close()\n",
    "\n",
    "def on_error(ws, error):\n",
    "    print(\"### Error ###\")\n",
    "    print(error)\n",
    "    print(\"Reconnecting...\")\n",
    "    time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "    try:\n",
    "        ws.run_forever()\n",
    "    except Exception as e:\n",
    "        print(\"Reconnection failed:\", e)\n",
    "\n",
    "def on_close(ws, close_status_code, close_msg):\n",
    "    pass\n",
    "\n",
    "def create_websocket(offset):\n",
    "    global cookies\n",
    "    ws = websocket.WebSocketApp(\n",
    "        \"wss://bexar.tx.publicsearch.us/ws\",\n",
    "        on_open=lambda ws: on_open(ws),\n",
    "        on_message=on_message,\n",
    "        on_error=on_error,\n",
    "        on_close=on_close,\n",
    "        cookie=cookies\n",
    "    )\n",
    "    ws.custom_offset = offset  # Attach custom attribute for offset\n",
    "    return ws\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Geting tockens automatically\n",
    "    driver_get_tokens()\n",
    "    \n",
    "    websocket.enableTrace(False)  # Set to True for debugging\n",
    "    start_date = datetime.strptime(\"20241201\", \"%Y%m%d\")\n",
    "    end_today = datetime.now()\n",
    "\n",
    "    while start_date < end_today:\n",
    "        # Calculate the end of the current month\n",
    "        end_date = start_date + timedelta(days=20)\n",
    "        if end_date > end_today:\n",
    "            end_date = end_today\n",
    "\n",
    "        # Process records for the current month\n",
    "        offset = 0\n",
    "        ws = create_websocket(offset)\n",
    "        ws.run_forever()\n",
    "\n",
    "        if response_data:\n",
    "            try:\n",
    "                json_response = json.loads(response_data)\n",
    "                data_docs = json_response[\"payload\"][\"data\"][\"byHash\"]\n",
    "                total_records = json_response[\"payload\"][\"meta\"][\"numRecords\"]\n",
    "                print(\"Total_rec \",total_records)\n",
    "                if total_records > 10000:\n",
    "                    end_date = end_date - timedelta(days=13)\n",
    "                    ws = create_websocket(offset)\n",
    "                    ws.run_forever()\n",
    "                    json_response = json.loads(response_data)\n",
    "                    data_docs = json_response[\"payload\"][\"data\"][\"byHash\"]\n",
    "                    total_records = json_response[\"payload\"][\"meta\"][\"numRecords\"]\n",
    "                    print(\"Total_rec2 \",total_records)\n",
    "                fina_data.update(data_docs)\n",
    "                print(f\"Records collected: {len(fina_data)}\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Error: Unable to decode JSON response.\")\n",
    "        else:\n",
    "            print(\"No response received.\")\n",
    "\n",
    "        # Fetch remaining records for the month\n",
    "        for offset in tqdm(range(250, total_records, 250), desc=\"Fetching records\"):\n",
    "            ws = create_websocket(offset)\n",
    "            ws.run_forever()\n",
    "\n",
    "            if response_data:\n",
    "                try:\n",
    "                    json_response = json.loads(response_data)\n",
    "                    data_docs = json_response[\"payload\"][\"data\"][\"byHash\"]\n",
    "                    fina_data.update(data_docs)\n",
    "                    print(f\"Records collected: {len(fina_data)}\")\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Error: Unable to decode JSON response.\")\n",
    "            else:\n",
    "                print(\"No response received.\")\n",
    "\n",
    "        # Move to the next month\n",
    "        start_date = end_date + timedelta(days=1)\n",
    "    final_time = datetime.now()\n",
    "    print(final_time - end_today)\n",
    "    print(\"### Data Collection Complete ###\")\n",
    "    print(f\"Total records collected: {len(fina_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea933a6-1a03-4511-bf1f-e0413b39f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54936398-63fe-48da-bbaf-a943e408e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14847c2e-44af-4cb9-8486-a31a18570002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"BexarData1-30-2025.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb3ce72a-3d00-4505-b0be-d746910f038f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 4, 7, 0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a304249f-c3d0-462f-b24e-e86e59280be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117045"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fina_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e8942-118d-4c05-9e8a-09cb3a966d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
